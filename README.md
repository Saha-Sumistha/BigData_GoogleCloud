# BigData_GoogleCloud
## GA 1
* Spin Up a VM
* write a python program to count lines of a file placed in GCS
* A text file containing the output
## GA 2
* Python program to count the lines of a file that is placed in GCS using Google Cloud Functions
## GA 3
* A spark code for executing a Hashing example on the public file: gs://bucket_two_2/hash_file.txt .
* To find the number of user clicks between 0-6, 6-12, 12-18, and 18-24.
* A text file containing the output.
## GA 4
* PySpark code to implement SCD Type II on a customer master data frame.
* Python file with the code.
* A text file containing the output.
## GA 5
* SparkSQL code to implement SCD Type II on a customer master data frame.
* Python file with the code.
* A text file containing the output.
## GA 6
* Count the number of lines in a file uploaded to GCS bucket in real-time by using Google Cloud Functions and Pub/Sub.
* A Google cloud Function which gets triggered whenever a file is added to a bucket and publishes the file name to a topic in Pub/Sub.
* A python file, which acts as a subscriber to this topic and prints out the number of lines in the file in real-time.
## GA 7
* Stream the data stored on the GCS bucket into Kafka by breaking the data into batches of 10 records that are written to Kafka separated by a sleep time of 10 seconds until 100 records are written.
* Use Spark Streaming to read from Kafka every 5 seconds and emit the count of rows seen in the last 10 seconds.
## GA 8
* Convert the Spark MLlib code shown at https://docs.databricks.com/_extras/notebooks/source/decision-trees.html to use the CrossValidator autotuner &amp; report on the best performing model Parameters.
